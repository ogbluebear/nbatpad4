{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMT4aXBj288p",
        "outputId": "789613a1-b024-41e3-b26c-92885dbb7dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "VeQJI3ps2dXO",
        "outputId": "aa53b54b-f5d4-4eee-e69a-4f7e2f7c4bbb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2d06b3f4c395>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, SimpleRNN\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad93mjXcLcWp"
      },
      "source": [
        "---\n",
        "## Linux_Disk Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aGKe7ls-ft_"
      },
      "outputs": [],
      "source": [
        "  class Model:\n",
        "      def __init__(self):\n",
        "          self.fcn = None\n",
        "          self.rf = None\n",
        "\n",
        "      def filter_scanning(self, df):\n",
        "          #change K and M\n",
        "          def convert_percentage_to_float(value):\n",
        "            if value == '-':\n",
        "                value = 0\n",
        "            if isinstance(value, (float, int)):\n",
        "                return float(value)\n",
        "            if value.endswith('%'):\n",
        "                value = float(value[:-1]) / 100\n",
        "            return value\n",
        "          def convert_to_float(value):\n",
        "            if value == '-':\n",
        "                value = 0\n",
        "            if isinstance(value, (float, int)):\n",
        "                return float(value)\n",
        "            if value.endswith('K'):\n",
        "                value = float(value[:-1]) * 1000\n",
        "            elif value.endswith('M'):\n",
        "                value = float(value[:-1]) * 1000000\n",
        "            else:\n",
        "                value = float(value)\n",
        "            return value\n",
        "\n",
        "          df['RDDSK'] = df['RDDSK'].apply(convert_to_float)\n",
        "          df['WRDSK'] = df['WRDSK'].apply(convert_to_float)\n",
        "          df['WCANCL'] = df['WCANCL'].apply(convert_to_float)\n",
        "\n",
        "          df['DSK'] = df['DSK'].apply(convert_percentage_to_float)\n",
        "\n",
        "          le = LabelEncoder()\n",
        "          df['CMD'] = le.fit_transform(df['CMD'])\n",
        "\n",
        "          scanning_count = df[df['type'] == 'scanning'].shape[0]\n",
        "\n",
        "          # 2. Delete all rows that don't have 'scanning' or 'normal' in the 'type' column\n",
        "          df = df[df['type'].isin(['scanning', 'normal'])]\n",
        "\n",
        "          # Filter rows that have 'normal' in the 'type' column\n",
        "          normal_rows = df[df['type'] == 'normal']\n",
        "\n",
        "          # Calculate the number of rows to drop\n",
        "          type_counts = df['type'].value_counts()\n",
        "          rows_to_drop = type_counts['normal'] - scanning_count\n",
        "\n",
        "          # Randomly select 'rows_to_drop' row indices to drop\n",
        "          drop_indices = np.random.choice(normal_rows.index, rows_to_drop, replace=False)\n",
        "\n",
        "          # Drop the selected rows from the DataFrame\n",
        "          df = df.drop(drop_indices)\n",
        "\n",
        "          df.drop(columns=['type', 'WCANCL'], inplace=True)\n",
        "\n",
        "          return df\n",
        "\n",
        "      def load_data(self, path):\n",
        "          # Load the dataset\n",
        "          df = pd.read_csv(path)\n",
        "          df = self.filter_scanning(df)\n",
        "\n",
        "          # Impute missing values with the mean value\n",
        "          imputer = SimpleImputer(strategy='mean')\n",
        "          df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "          # Split the dataset into training, validation, and testing sets\n",
        "          X_trainval, X_test, y_trainval, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1],\n",
        "                                                                    test_size=0.2, stratify=df.iloc[:, -1],\n",
        "                                                                    random_state=42)\n",
        "          X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval,\n",
        "                                                            test_size=0.25, stratify=y_trainval,\n",
        "                                                            random_state=42)\n",
        "\n",
        "          # Normalize the numerical features\n",
        "          scaler = StandardScaler()\n",
        "          X_train = scaler.fit_transform(X_train)\n",
        "          X_val = scaler.transform(X_val)\n",
        "          X_test = scaler.transform(X_test)\n",
        "\n",
        "          self.X_train, self.X_val, self.X_test = X_train, X_val, X_test\n",
        "          self.y_train, self.y_val, self.y_test = y_train, y_val, y_test\n",
        "\n",
        "      def train_cnn(self, epochs=10, batch_size=32):\n",
        "          # Reshape the input for the CNN\n",
        "          X_train_cnn = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "          X_val_cnn = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "          # Define the CNN architecture\n",
        "          self.cnn = tf.keras.models.Sequential([\n",
        "              Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "              MaxPooling1D(pool_size=2),\n",
        "              Flatten(),\n",
        "              Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the CNN\n",
        "          self.cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the CNN\n",
        "          self.cnn.fit(X_train_cnn, self.y_train, validation_data=(X_val_cnn, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_cnn(self):\n",
        "          # Reshape the input for the CNN\n",
        "          X_test_cnn = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "          # Evaluate the CNN\n",
        "          y_prob = self.cnn.predict(X_test_cnn)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('CNN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('CNN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('CNN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "                  # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('CNN TPR:', tpr)\n",
        "          print('CNN FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "          np.save('CNN_fpr.npy', fpr)\n",
        "          np.save('CNN_tpr.npy', tpr)\n",
        "\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('CNN ROC AUC:', roc_auc)\n",
        "\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "\n",
        "          # Get the indices of fpr elements that are less than or equal to 0.01\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "\n",
        "          # Get the maximum tpr corresponding to fpr <= 0.01\n",
        "          max_tpr = tpr[indices].max()\n",
        "\n",
        "          # Get the index of the maximum tpr\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "          print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 0.5])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()\n",
        "\n",
        "      def train_lstm(self, epochs=10, batch_size=32):\n",
        "          # Reshape the input for the LSTM\n",
        "          X_train_lstm = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "          X_val_lstm = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "          # Define the LSTM architecture\n",
        "          self.lstm = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.LSTM(32, activation='relu', input_shape=(X_train_lstm.shape[1], 1)),\n",
        "              tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the LSTM\n",
        "          self.lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the LSTM\n",
        "          self.lstm.fit(X_train_lstm, self.y_train, validation_data=(X_val_lstm, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_lstm(self):\n",
        "          # Reshape the input for the LSTM\n",
        "          X_test_lstm = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "          # Evaluate the LSTM\n",
        "          y_prob = self.lstm.predict(X_test_lstm)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('LSTM accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('LSTM confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('LSTM classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('LSTM TPR:', tpr)\n",
        "          print('LSTM FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "          np.save('LSTM_fpr.npy', fpr)\n",
        "          np.save('LSTM_tpr.npy', tpr)\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('LSTM ROC AUC:', roc_auc)\n",
        "\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "\n",
        "          # Get the indices of fpr elements that are less than or equal to 0.01\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "\n",
        "          # Get the maximum tpr corresponding to fpr <= 0.01\n",
        "          max_tpr = tpr[indices].max()\n",
        "\n",
        "          # Get the index of the maximum tpr\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "          print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 0.5])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()\n",
        "\n",
        "      def train_fcn(self, epochs=10, batch_size=32):\n",
        "          # Define the FCN architecture\n",
        "          self.fcn = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Dense(32, activation='relu', input_shape=(self.X_train.shape[1],)),\n",
        "              tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the FCN\n",
        "          self.fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the FCN\n",
        "          self.fcn.fit(self.X_train, self.y_train, validation_data=(self.X_val, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_fcn(self):\n",
        "          # Evaluate the FCN\n",
        "          y_prob = self.fcn.predict(self.X_test)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('FCN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('FCN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('FCN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('FCN TPR:', tpr)\n",
        "          print('FCN FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "\n",
        "          np.save('FCN_fpr.npy', fpr)\n",
        "          np.save('FCN_tpr.npy', tpr)\n",
        "\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('FCN ROC AUC:', roc_auc)\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "          max_tpr = tpr[indices].max()\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "          print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 1.0])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()\n",
        "\n",
        "      def train_cnn_lstm(self, epochs=10, batch_size=32):\n",
        "          # Reshape the input for the CNN-LSTM\n",
        "          X_train_cnn_lstm = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "          X_val_cnn_lstm = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "          # Define the CNN-LSTM architecture\n",
        "          self.cnn_lstm = tf.keras.models.Sequential([\n",
        "              Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn_lstm.shape[1], 1)),\n",
        "              MaxPooling1D(pool_size=2),\n",
        "              LSTM(64),\n",
        "              Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the CNN-LSTM\n",
        "          self.cnn_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the CNN-LSTM\n",
        "          self.cnn_lstm.fit(X_train_cnn_lstm, self.y_train, validation_data=(X_val_cnn_lstm, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_cnn_lstm(self):\n",
        "          # Reshape the input for the CNN-LSTM\n",
        "          X_test_cnn_lstm = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "          # Evaluate the CNN-LSTM\n",
        "          y_prob = self.cnn_lstm.predict(X_test_cnn_lstm)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('CNN-LSTM accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('CNN-LSTM confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('CNN-LSTM classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('CNN-LSTM TPR:', tpr)\n",
        "          print('CNN-LSTM FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "\n",
        "          np.save('CNN_LSTM_fpr.npy', fpr)\n",
        "          np.save('CNN_LSTM_tpr.npy', tpr)\n",
        "\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('FCN ROC AUC:', roc_auc)\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "          max_tpr = tpr[indices].max()\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "          print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 1.0])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()\n",
        "\n",
        "      def train_rf(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "          # Define the Random Forest classifier\n",
        "          self.rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
        "                                            min_samples_split=min_samples_split,\n",
        "                                            min_samples_leaf=min_samples_leaf,\n",
        "                                            random_state=42)\n",
        "\n",
        "          # Train the Random Forest classifier\n",
        "          self.rf.fit(self.X_train, self.y_train)\n",
        "\n",
        "      def evaluate_rf(self):\n",
        "          # Evaluate the Random Forest classifier\n",
        "          y_pred = self.rf.predict(self.X_test)\n",
        "          print('RF accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('RF confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('RF classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('RF TPR:', tpr)\n",
        "          print('RF FPR:', fpr)\n",
        "\n",
        "      def train_rnn(self, epochs=10, batch_size=32):\n",
        "          # Reshape the input for the RNN\n",
        "          X_train_rnn = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "          X_val_rnn = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "          # Define the RNN architecture\n",
        "          self.rnn = tf.keras.models.Sequential([\n",
        "              SimpleRNN(32, activation='relu', input_shape=(X_train_rnn.shape[1], 1)),\n",
        "              Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the RNN\n",
        "          self.rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the RNN\n",
        "          self.rnn.fit(X_train_rnn, self.y_train, validation_data=(X_val_rnn, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_rnn(self):\n",
        "          # Reshape the input for the RNN\n",
        "          X_test_rnn = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "          # Evaluate the RNN\n",
        "          y_prob = self.rnn.predict(X_test_rnn)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('RNN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('RNN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('RNN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('RNN TPR:', tpr)\n",
        "          print('RNN FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "          np.save('RNN_fpr.npy', fpr)\n",
        "          np.save('RNN_tpr.npy', tpr)\n",
        "\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('FCN ROC AUC:', roc_auc)\n",
        "\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "\n",
        "          # Get the indices of fpr elements that are less than or equal to 0.05\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "\n",
        "          # Get the maximum tpr corresponding to fpr <= 0.01\n",
        "          max_tpr = tpr[indices].max()\n",
        "\n",
        "          # Get the index of the maximum tpr\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 1.0])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()\n",
        "\n",
        "      def train_ann(self, epochs=10, batch_size=32):\n",
        "          # Define the ANN architecture\n",
        "          self.ann = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Dense(32, activation='relu', input_shape=(self.X_train.shape[1],)),\n",
        "              tf.keras.layers.Dense(64, activation='relu'),\n",
        "              tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "          ])\n",
        "\n",
        "          # Compile the ANN\n",
        "          self.ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "          # Train the ANN\n",
        "          self.ann.fit(self.X_train, self.y_train, validation_data=(self.X_val, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "      def evaluate_ann(self):\n",
        "          # Evaluate the ANN\n",
        "          y_prob = self.ann.predict(self.X_test)\n",
        "          y_pred = np.round(y_prob).astype(int)\n",
        "          print('ANN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "          print('ANN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "          print('ANN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "          # Calculate TPR and FPR\n",
        "          cm = confusion_matrix(self.y_test, y_pred)\n",
        "          tn, fp, fn, tp = cm.ravel()\n",
        "          tpr = tp / (tp + fn)\n",
        "          fpr = fp / (fp + tn)\n",
        "          print('ANN TPR:', tpr)\n",
        "          print('ANN FPR:', fpr)\n",
        "\n",
        "          # Calculate ROC AUC\n",
        "          fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "          np.save('ANN_fpr.npy', fpr)\n",
        "          np.save('ANN_tpr.npy', tpr)\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          print('FCN ROC AUC:', roc_auc)\n",
        "          idx = np.abs(fpr - 0.01).argmin()\n",
        "          indices = np.where(fpr <= 0.01)[0]\n",
        "          max_tpr = tpr[indices].max()\n",
        "          idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "          print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "          print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "          # Plot ROC curve\n",
        "          plt.figure()\n",
        "          plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "          plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "          plt.xlim([0.0, 0.5])\n",
        "          plt.ylim([0.0, 1.05])\n",
        "          plt.xlabel('False Positive Rate')\n",
        "          plt.ylabel('True Positive Rate')\n",
        "          plt.title('Receiver Operating Characteristic')\n",
        "          plt.legend(loc=\"lower right\")\n",
        "          plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oREnwtBLgGs"
      },
      "outputs": [],
      "source": [
        "clf=Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upSuYCoaLjRK",
        "outputId": "0706066d-fc0e-41e2-85af-9542b9e77f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-37c9fa9d8f6e>:62: DtypeWarning: Columns (2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n"
          ]
        }
      ],
      "source": [
        "clf.load_data('drive/MyDrive/ToN_IoT/Train_Test_datasets/Train_Test_Linux_dataset/linux_disk.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.train_cnn()\n",
        "clf.evaluate_cnn()\n",
        "\n",
        "#TPR after 0.01FPR: 0.20515099223468508"
      ],
      "metadata": {
        "id": "lt_uzpULDdyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.train_lstm()\n",
        "clf.evaluate_lstm()\n",
        "\n",
        "#TPR: 0.979025435\n",
        "#TPR after 0.01 FPR rule: 0.48090046278139464"
      ],
      "metadata": {
        "id": "KnCjN3t9DgD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zU-eWYaif0j"
      },
      "outputs": [],
      "source": [
        "clf.train_fcn()\n",
        "clf.evaluate_fcn()\n",
        "\n",
        "#FCN TPR: 0.979370931053416\n",
        "#Maximum TPR with FPR <= 0.01:  0.26194132873166525"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zubCsUCMParP"
      },
      "outputs": [],
      "source": [
        "clf.train_cnn_lstm()\n",
        "clf.evaluate_cnn_lstm()\n",
        "\n",
        "#CNN-LSTM TPR: 0.9710565534551729 (8.2%)\n",
        "#Maximum TPR with FPR <= 0.01:  0.5407082908463409"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyVXZ8JpSFVU"
      },
      "outputs": [],
      "source": [
        "clf.train_rnn()\n",
        "clf.evaluate_rnn()\n",
        "\n",
        "#RNN TPR: 0.9675268648521452 (6% FPR)\n",
        "#Maximum TPR with FPR <= 0.01:  0.6173817554317985"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x3E0uzAZ3XB"
      },
      "outputs": [],
      "source": [
        "clf.train_ann()\n",
        "clf.evaluate_ann()\n",
        "\n",
        "#ANN TPR: 0.9871362459800769\n",
        "#Maximum TPR with FPR <= 0.01:  0.4516401286375402"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISD9AaLZjfpn"
      },
      "outputs": [],
      "source": [
        "clf.train_rf()\n",
        "clf.evaluate_rf()\n",
        "\n",
        "#RF TPR: 0.9967840614950192"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfFtxbjimZvn"
      },
      "source": [
        "---\n",
        "## Linux_Process Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgFWxDApmd2Z"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.fcn = None\n",
        "        self.rf = None\n",
        "\n",
        "    def preprocess_linux_process(self, df):\n",
        "        le = LabelEncoder()\n",
        "        df['POLI'] = le.fit_transform(df['POLI'])\n",
        "        df['Status'] = le.fit_transform(df['Status'])\n",
        "        df['State'] = le.fit_transform(df['State'])\n",
        "        df['CMD'] = le.fit_transform(df['CMD'])\n",
        "\n",
        "        scanning_count = df[df['type'] == 'scanning'].shape[0]\n",
        "\n",
        "        # 2. Delete all rows that don't have 'scanning' or 'normal' in the 'type' column\n",
        "        df = df[df['type'].isin(['scanning', 'normal'])]\n",
        "\n",
        "        # Filter rows that have 'normal' in the 'type' column\n",
        "        normal_rows = df[df['type'] == 'normal']\n",
        "\n",
        "        # Calculate the number of rows to drop\n",
        "        type_counts = df['type'].value_counts()\n",
        "        rows_to_drop = type_counts['normal'] - scanning_count\n",
        "\n",
        "        # Randomly select 'rows_to_drop' row indices to drop\n",
        "        drop_indices = np.random.choice(normal_rows.index, rows_to_drop, replace=False)\n",
        "\n",
        "        # Drop the selected rows from the DataFrame\n",
        "        df = df.drop(drop_indices)\n",
        "\n",
        "        df.drop(columns=['type'], inplace=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def load_data(self, path):\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(path)\n",
        "        df = self.preprocess_linux_process(df)\n",
        "\n",
        "        # Impute missing values with the mean value\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "        # Split the dataset into training, validation, and testing sets\n",
        "        X_trainval, X_test, y_trainval, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1],\n",
        "                                                                  test_size=0.2, stratify=df.iloc[:, -1],\n",
        "                                                                  random_state=42)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval,\n",
        "                                                          test_size=0.25, stratify=y_trainval,\n",
        "                                                          random_state=42)\n",
        "\n",
        "        # Normalize the numerical features\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_val = scaler.transform(X_val)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        self.X_train, self.X_val, self.X_test = X_train, X_val, X_test\n",
        "        self.y_train, self.y_val, self.y_test = y_train, y_val, y_test\n",
        "    def train_cnn(self, epochs=10, batch_size=32):\n",
        "        # Reshape the input for the CNN\n",
        "        X_train_cnn = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "        X_val_cnn = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "        # Define the CNN architecture\n",
        "        self.cnn = tf.keras.models.Sequential([\n",
        "            Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            Flatten(),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the CNN\n",
        "        self.cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the CNN\n",
        "        self.cnn.fit(X_train_cnn, self.y_train, validation_data=(X_val_cnn, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_cnn(self):\n",
        "        # Reshape the input for the CNN\n",
        "        X_test_cnn = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "        # Evaluate the CNN\n",
        "        y_prob = self.cnn.predict(X_test_cnn)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('CNN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('CNN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('CNN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "                # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('CNN TPR:', tpr)\n",
        "        print('CNN FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('CNN_fpr.npy', fpr)\n",
        "        np.save('CNN_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('CNN ROC AUC:', roc_auc)\n",
        "\n",
        "        idx = np.abs(fpr - 0.01).argmin()\n",
        "\n",
        "        # Get the indices of fpr elements that are less than or equal to 0.01\n",
        "        indices = np.where(fpr <= 0.01)[0]\n",
        "\n",
        "        # Get the maximum tpr corresponding to fpr <= 0.01\n",
        "        max_tpr = tpr[indices].max()\n",
        "\n",
        "        # Get the index of the maximum tpr\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def train_lstm(self, epochs=10, batch_size=32):\n",
        "        # Reshape the input for the LSTM\n",
        "        X_train_lstm = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "        X_val_lstm = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "        # Define the LSTM architecture\n",
        "        self.lstm = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.LSTM(32, activation='relu', input_shape=(X_train_lstm.shape[1], 1)),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the LSTM\n",
        "        self.lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the LSTM\n",
        "        self.lstm.fit(X_train_lstm, self.y_train, validation_data=(X_val_lstm, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_lstm(self):\n",
        "        # Reshape the input for the LSTM\n",
        "        X_test_lstm = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "        # Evaluate the LSTM\n",
        "        y_prob = self.lstm.predict(X_test_lstm)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('LSTM accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('LSTM confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('LSTM classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('LSTM TPR:', tpr)\n",
        "        print('LSTM FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('LSTM_fpr.npy', fpr)\n",
        "        np.save('LSTM_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('LSTM ROC AUC:', roc_auc)\n",
        "\n",
        "        idx = np.abs(fpr - 0.01).argmin()\n",
        "\n",
        "        # Get the indices of fpr elements that are less than or equal to 0.01\n",
        "        indices = np.where(fpr <= 0.01)[0]\n",
        "\n",
        "        # Get the maximum tpr corresponding to fpr <= 0.01\n",
        "        max_tpr = tpr[indices].max()\n",
        "\n",
        "        # Get the index of the maximum tpr\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def train_fcn(self, epochs=10, batch_size=32):\n",
        "        # Define the FCN architecture\n",
        "        self.fcn = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(32, activation='relu', input_shape=(self.X_train.shape[1],)),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the FCN\n",
        "        self.fcn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the FCN\n",
        "        self.fcn.fit(self.X_train, self.y_train, validation_data=(self.X_val, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_fcn(self):\n",
        "        # Evaluate the FCN\n",
        "        y_prob = self.fcn.predict(self.X_test)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('FCN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('FCN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('FCN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('FCN TPR:', tpr)\n",
        "        print('FCN FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('FCN_fpr.npy', fpr)\n",
        "        np.save('FCN_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('FCN ROC AUC:', roc_auc)\n",
        "        idx = np.abs(fpr - 0.01).argmin()\n",
        "        indices = np.where(fpr <= 0.01)[0]\n",
        "        max_tpr = tpr[indices].max()\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def train_cnn_lstm(self, epochs=10, batch_size=32):\n",
        "        # Reshape the input for the CNN-LSTM\n",
        "        X_train_cnn_lstm = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "        X_val_cnn_lstm = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "        # Define the CNN-LSTM architecture\n",
        "        self.cnn_lstm = tf.keras.models.Sequential([\n",
        "            Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn_lstm.shape[1], 1)),\n",
        "            MaxPooling1D(pool_size=2),\n",
        "            LSTM(64),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the CNN-LSTM\n",
        "        self.cnn_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the CNN-LSTM\n",
        "        self.cnn_lstm.fit(X_train_cnn_lstm, self.y_train, validation_data=(X_val_cnn_lstm, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_cnn_lstm(self):\n",
        "        # Reshape the input for the CNN-LSTM\n",
        "        X_test_cnn_lstm = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "        # Evaluate the CNN-LSTM\n",
        "        y_prob = self.cnn_lstm.predict(X_test_cnn_lstm)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('CNN-LSTM accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('CNN-LSTM confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('CNN-LSTM classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('CNN-LSTM TPR:', tpr)\n",
        "        print('CNN-LSTM FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('CNN_LSTM_fpr.npy', fpr)\n",
        "        np.save('CNN_LSTM_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('FCN ROC AUC:', roc_auc)\n",
        "        idx = np.abs(fpr - 0.01).argmin()\n",
        "        indices = np.where(fpr <= 0.01)[0]\n",
        "        max_tpr = tpr[indices].max()\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def train_rf(self, n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "        # Define the Random Forest classifier\n",
        "        self.rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
        "                                          min_samples_split=min_samples_split,\n",
        "                                          min_samples_leaf=min_samples_leaf,\n",
        "                                          random_state=42)\n",
        "\n",
        "        # Train the Random Forest classifier\n",
        "        self.rf.fit(self.X_train, self.y_train)\n",
        "\n",
        "    def evaluate_rf(self):\n",
        "        # Evaluate the Random Forest classifier\n",
        "        y_pred = self.rf.predict(self.X_test)\n",
        "        print('RF accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('RF confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('RF classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('RF TPR:', tpr)\n",
        "        print('RF FPR:', fpr)\n",
        "\n",
        "    def train_rnn(self, epochs=10, batch_size=32):\n",
        "        # Reshape the input for the RNN\n",
        "        X_train_rnn = self.X_train.reshape(self.X_train.shape[0], self.X_train.shape[1], 1)\n",
        "        X_val_rnn = self.X_val.reshape(self.X_val.shape[0], self.X_val.shape[1], 1)\n",
        "\n",
        "        # Define the RNN architecture\n",
        "        self.rnn = tf.keras.models.Sequential([\n",
        "            SimpleRNN(32, activation='relu', input_shape=(X_train_rnn.shape[1], 1)),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the RNN\n",
        "        self.rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the RNN\n",
        "        self.rnn.fit(X_train_rnn, self.y_train, validation_data=(X_val_rnn, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_rnn(self):\n",
        "        # Reshape the input for the RNN\n",
        "        X_test_rnn = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1], 1)\n",
        "\n",
        "        # Evaluate the RNN\n",
        "        y_prob = self.rnn.predict(X_test_rnn)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('RNN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('RNN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('RNN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('RNN TPR:', tpr)\n",
        "        print('RNN FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('RNN_fpr.npy', fpr)\n",
        "        np.save('RNN_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('FCN ROC AUC:', roc_auc)\n",
        "        idx = np.abs(fpr - 0.011).argmin()\n",
        "        indices = np.where(fpr <= 0.011)[0]\n",
        "        max_tpr = tpr[indices].max()\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def train_ann(self, epochs=10, batch_size=32):\n",
        "        # Define the ANN architecture\n",
        "        self.ann = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(32, activation='relu', input_shape=(self.X_train.shape[1],)),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        # Compile the ANN\n",
        "        self.ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Train the ANN\n",
        "        self.ann.fit(self.X_train, self.y_train, validation_data=(self.X_val, self.y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def evaluate_ann(self):\n",
        "        # Evaluate the ANN\n",
        "        y_prob = self.ann.predict(self.X_test)\n",
        "        y_pred = np.round(y_prob).astype(int)\n",
        "        print('ANN accuracy:', accuracy_score(self.y_test, y_pred))\n",
        "        print('ANN confusion matrix:\\n', confusion_matrix(self.y_test, y_pred))\n",
        "        print('ANN classification report:\\n', classification_report(self.y_test, y_pred, digits=4))\n",
        "\n",
        "        # Calculate TPR and FPR\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn)\n",
        "        fpr = fp / (fp + tn)\n",
        "        print('ANN TPR:', tpr)\n",
        "        print('ANN FPR:', fpr)\n",
        "\n",
        "        # Calculate ROC AUC\n",
        "        fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
        "        np.save('ANN_fpr.npy', fpr)\n",
        "        np.save('ANN_tpr.npy', tpr)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        print('FCN ROC AUC:', roc_auc)\n",
        "        idx = np.abs(fpr - 0.01).argmin()\n",
        "        indices = np.where(fpr <= 0.01)[0]\n",
        "        max_tpr = tpr[indices].max()\n",
        "        idx_max_tpr = np.where(tpr == max_tpr)[0][0]\n",
        "\n",
        "        print(\"Maximum TPR with FPR <= 0.01: \", max_tpr)\n",
        "        print(\"Corresponding FPR: \", fpr[idx_max_tpr])\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6ovNcqaoNfg"
      },
      "outputs": [],
      "source": [
        "clf = Model()\n",
        "clf.load_data('drive/MyDrive/ToN_IoT/Train_Test_datasets/Train_Test_Linux_dataset/linux_process.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.train_cnn()\n",
        "clf.evaluate_cnn()"
      ],
      "metadata": {
        "id": "75MpmCNeATx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.train_lstm()\n",
        "clf.evaluate_lstm()"
      ],
      "metadata": {
        "id": "lsyIlEmLAWRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHzC9Zl4ykKW"
      },
      "outputs": [],
      "source": [
        "clf.train_fcn()\n",
        "clf.evaluate_fcn()\n",
        "\n",
        "#FCN TPR: 0.9899869960988297 (0.09% FPR)\n",
        "#Maximum TPR with FPR <= 0.01:  0.9260078023407022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh-hyTDOykKc"
      },
      "outputs": [],
      "source": [
        "clf.train_cnn_lstm()\n",
        "clf.evaluate_cnn_lstm()\n",
        "\n",
        "#CNN-LSTM TPR: 0.9947984395318595 (10 Percent FPR)\n",
        "#Maximum TPR with FPR <= 0.01:  0.9433029908972692"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBGjPGBsykKc"
      },
      "outputs": [],
      "source": [
        "clf.train_rnn()\n",
        "clf.evaluate_rnn()\n",
        "\n",
        "#RNN TPR: 0.9849154746423927 (0.015%)\n",
        "#Maximum TPR with FPR <= 0.01:  0.9837451235370611"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPsEsbaMykKc"
      },
      "outputs": [],
      "source": [
        "clf.train_ann()\n",
        "clf.evaluate_ann()\n",
        "\n",
        "#ANN TPR: 0.9876462938881665 (8.4%)\n",
        "#Maximum TPR with FPR <= 0.01:  0.9677503250975292"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSTyEgjsykKd"
      },
      "outputs": [],
      "source": [
        "clf.train_rf()\n",
        "clf.evaluate_rf()\n",
        "\n",
        "#RF TPR: 0.9942782834850455"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ad93mjXcLcWp",
        "kfFtxbjimZvn"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}